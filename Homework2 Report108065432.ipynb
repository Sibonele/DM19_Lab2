{
 "cells": [
  {
   "attachments": {
    "Leader%20Board.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:Sibongakonke Zungu\n",
    "\n",
    "Student ID:108065432\n",
    "\n",
    "GitHub ID:Sibonele\n",
    "\n",
    "Kaggle name: Sibongakonke Zungu\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "\n",
    "\n",
    "![Leader%20Board.PNG](attachment:Leader%20Board.PNG)\n",
    "\n",
    "[Snapshot](img/pic0.png)\n",
    "https://www.kaggle.com/c/dm19-lab2-kaggle-competition-2/leaderboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps taken\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "Libraries importating\n",
    "Data source\n",
    "Data importing\n",
    "Normalization of json file\n",
    "Renaming column headers\n",
    "\n",
    "# Feature Engineering\n",
    " * Training set\n",
    " * Test set\n",
    "Text tokenization \n",
    " * from nltk.tokenize import TweetTokenizer\n",
    " I used this tokenizer as I am working with tweets and tweetTokenizer deals with tweets very well\n",
    " \n",
    "Vectorizer\n",
    " * from sklearn.feature_extraction.text import CountVectorizer\n",
    " * from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    " \n",
    "# Model training\n",
    "Logistic Regresion.\n",
    " * makes use of the log function as it makes use of the several predcitorcs which are readily available, thus for the emotion prediction we ecpected \n",
    " \n",
    "# Saving of results\n",
    " * saved the result in a csvfile (to.csv)\n",
    " * Opened the file to create headers\n",
    " * Created and ordered file\n",
    " \n",
    "# Competion CSV file submissions\n",
    " * 9 Submissions we're made\n",
    " \n",
    "# Discussion and Conclusion\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries importating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "\n",
    "Data from the tweets are provided as a json file and test and two csv files which contain Data Identification and emotions. This data is from the Data mining class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "file = open(\"../input//dm19-lab2-nthu/tweets_DM.json\", 'r', encoding='utf-8')\n",
    "data = []\n",
    "for line in file.readlines():\n",
    "    dic = json.loads(line)\n",
    "\n",
    "    data.append(dic)\n",
    "\n",
    "data_id = pd.read_csv(\"../input/dm19-lab2-nthu/data_identification.csv\" ,sep=\",\")\n",
    "emotion = pd.read_csv(\"../input/dm19-lab2-nthu/emotion.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>inde</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score            inde                 date    type  \\\n",
       "0    391  hashtag_tweets  2015-05-23 11:42:47  tweets   \n",
       "1    433  hashtag_tweets  2016-01-28 04:52:09  tweets   \n",
       "2    232  hashtag_tweets  2017-12-25 04:39:20  tweets   \n",
       "3    376  hashtag_tweets  2016-01-24 23:53:05  tweets   \n",
       "4    989  hashtag_tweets  2016-01-08 17:18:59  tweets   \n",
       "\n",
       "                        hashtags  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                   [bibleverse]  0x28b412   \n",
       "3                             []  0x1cd5b0   \n",
       "4                             []  0x2de201   \n",
       "\n",
       "                                                text  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...  \n",
       "2  Confident of your obedience, I write to you, k...  \n",
       "3                Now ISSA is stalking Tasha 😂😂😂 <LH>  \n",
       "4  \"Trust is not the same as faith. A friend is s...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization of json file and changing of columns\n",
    "tweets_df = pd.DataFrame.from_dict(json_normalize(data), orient='columns')\n",
    "tweets_df=tweets_df.rename({'_score': 'score','_index': 'inde','_crawldate': 'date','_type': 'type'\n",
    "                           ,'_source.tweet.hashtags': 'hashtags','_source.tweet.tweet_id': 'tweet_id'\n",
    "                           , '_source.tweet.text': 'text'}, axis=1)\n",
    "tweets_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>inde</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score            inde                 date    type  \\\n",
       "0    391  hashtag_tweets  2015-05-23 11:42:47  tweets   \n",
       "1    433  hashtag_tweets  2016-01-28 04:52:09  tweets   \n",
       "2    232  hashtag_tweets  2017-12-25 04:39:20  tweets   \n",
       "3    376  hashtag_tweets  2016-01-24 23:53:05  tweets   \n",
       "4    989  hashtag_tweets  2016-01-08 17:18:59  tweets   \n",
       "\n",
       "                        hashtags  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                   [bibleverse]  0x28b412   \n",
       "3                             []  0x1cd5b0   \n",
       "4                             []  0x2de201   \n",
       "\n",
       "                                                text identification  \n",
       "0  People who post \"add me on #Snapchat\" must be ...          train  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...          train  \n",
       "2  Confident of your obedience, I write to you, k...           test  \n",
       "3                Now ISSA is stalking Tasha 😂😂😂 <LH>          train  \n",
       "4  \"Trust is not the same as faith. A friend is s...           test  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating one table from the json file containting tweets and merging it with  csv file data identification\n",
    "merged_df = pd.merge(tweets_df, data_id, on=\"tweet_id\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1867535, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#creating the training and test set\n",
    "train_df=merged_df[merged_df[\"identification\"] == \"train\"]\n",
    "test_df=merged_df[merged_df[\"identification\"] == \"test\"]\n",
    "\n",
    "#add the emotion column\n",
    "train_df=pd.merge(train_df,emotion, on=\"tweet_id\")\n",
    "test_df[\"emotion\"]=\"\"\n",
    "\n",
    "#dropping identification tags\n",
    "train_df.drop(columns=[\"identification\"],inplace=True)\n",
    "test_df.drop(columns=[\"identification\"],inplace=True)\n",
    "\n",
    "#using tweet_id as the index\n",
    "train_df.set_index(\"tweet_id\",inplace=True)\n",
    "test_df.set_index(\"tweet_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the df files to pickle file\n",
    "train_df.to_pickle(\"train_df.pkl\")\n",
    "test_df.to_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the pickle file\n",
    "train_df = pd.read_pickle(\"/kaggle/working/train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"/kaggle/working/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "token = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " 'Confident',\n",
       " 'of',\n",
       " 'your',\n",
       " 'obedience',\n",
       " ',',\n",
       " 'keep',\n",
       " 'pushing',\n",
       " '!',\n",
       " '!',\n",
       " '😂']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To make sure that the name of the user is left out, it does not become part of the tokenized sentence\n",
    "token = TweetTokenizer(strip_handles=True, reduce_len=True) \n",
    "x = '@wade: Confident of your obedience, keep pushing!!😂'\n",
    "token.tokenize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization \n",
    "\n",
    "Taking max features of 90000 and removing stopwords which are in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=90000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fb6df6cb080>>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "token = TweetTokenizer(preserve_case=False)\n",
    "tfidf = TfidfVectorizer(max_features=90000, stop_words='english',\n",
    "                                     tokenizer=token.tokenize)\n",
    "\n",
    "#fitting\n",
    "tfidf.fit(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455563, 90000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming training sets\n",
    "X_train = tfidf.transform(train_df['text'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972, 90000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming testing sets\n",
    "X_test = tfidf.transform(test_df['text'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pointers\n",
    "y_train = train_df['emotion']\n",
    "y_test = test_df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'sadness', 'anticipation', 'sadness', 'joy',\n",
       "       'anticipation', 'surprise', 'sadness', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build DecisionTree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.99\n",
      "testing accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00  411972.0\n",
      "       anger       0.00      0.00      0.00       0.0\n",
      "anticipation       0.00      0.00      0.00       0.0\n",
      "     disgust       0.00      0.00      0.00       0.0\n",
      "        fear       0.00      0.00      0.00       0.0\n",
      "         joy       0.00      0.00      0.00       0.0\n",
      "     sadness       0.00      0.00      0.00       0.0\n",
      "    surprise       0.00      0.00      0.00       0.0\n",
      "       trust       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00  411972.0\n",
      "   macro avg       0.00      0.00      0.00  411972.0\n",
      "weighted avg       0.00      0.00      0.00  411972.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=10,n_jobs=-1,max_iter=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pred_result = logreg.predict(X_test)\n",
    "logreg_pred_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'joy', ..., 'anticipation', 'joy',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pred_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using .to_csv to save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the result\n",
    "test_df['emotion']=logreg_pred_result\n",
    "test_df.index.rename('id',inplace=True)\n",
    "test_df.emotion.columns=['emotion']\n",
    "test_df.emotion.to_csv('submission002.csv',header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating column headers id and emotion \n",
    "sub22 = pd.read_csv(\"/kaggle/working/submission002.csv\",names=['id', 'emotion'],index_col = False )\n",
    "sub22.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412  anticipation\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a  anticipation\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e  anticipation\n",
       "411969  0x316b80  anticipation\n",
       "411970  0x29d0cb           joy\n",
       "411971  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result after column header creation\n",
    "sub22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub22.to_csv('submission002.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion and conclusion\n",
    " The more the max_features, the higher the accuraccy\n",
    " Logistic Regression was used because it does not take to long and I wanted to try a different modeling method than I am used     too\n",
    " Tried using descion trees and checkinng model accuracy but did not yield good results as it took hours to train and eventually had to stop the kernel. This lab exercise helped give me better understanding of what was being done in class and how we could apply the different methods for Natural Language processing."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
